{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Emily Cai\n",
    "- Jae Kim\n",
    "- Peter Shamoun\n",
    "- Viki Shi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  How well does the UC San Diego computer science curriculum prepare students skill-wise for industry needs in comparison to the other UCs based on the skills reported by developers in industry surveys in the past 5 years?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Computer science programs are designed to prepare students for successful careers in technology. However, industry technologies and required skills evolve rapidly—often outpacing curriculum updates—resulting in graduates who may lack the hands-on, current technical competencies demanded by employers. With a challenging tech job market and increasingly scarce new-graduate roles, concerns have grown that undergraduate programs, including the UC San Diego computer science program and the broader University of California curriculum, are not adequately preparing students for today's industry needs.\n",
    "\n",
    "This study evaluates the alignment between the UCSD and overall UC computer science curricula and the skills required in the tech industry. The analysis focuses on:\n",
    "- **Curriculum Content:** Reviewing course descriptions and curriculum goals.\n",
    "- **Industry Data:** Analyzing insights from recent Stack Overflow developer surveys and comparing them with current job market requirements.\n",
    "\n",
    "**Research Objectives and Measurement:**\n",
    "- **Intended Relationship:** The study seeks to determine the correlation between the curriculum’s technical content and the skills demanded by the tech industry. In particular, it examines whether courses covering emerging technologies like cloud computing, DevOps, containerization with Kubernetes and Docker adequately match the expertise employers seek.\n",
    "- **Measurement Metrics:** \n",
    "  - Quantifying the percentage of courses at UCSD and other UC campuses that include training in in-demand technologies.\n",
    "  - Comparing the success rate of UCSD graduates in securing tech roles with that of their peers from other UC institutions.\n",
    "  - Evaluating the representation of practical skills in the curriculum against their frequency in industry job postings.\n",
    "  - Using survey data to assess graduates’ proficiency in applied skills versus the theoretical emphasis in academic programs.\n",
    "\n",
    "Prior studies have underscored significant gaps between academic preparation and industry requirements. For example:\n",
    "- **[Closing the Gap between Software Engineering Education and Industrial Needs (Garousi et al., 2018)](https://arxiv.org/pdf/1812.01954)**  \n",
    "  This review of 33 studies from 12 countries found that graduates often lack hands-on skills in cloud computing, DevOps, and modern software development practices. It concluded that while universities emphasize theoretical knowledge, employers prioritize applied and soft skills, such as teamwork and communication.\n",
    "- **[The Gap between Higher Education and the Software Industry – A Case Study on Technology Differences (Dobslaw et al., 2023)](https://arxiv.org/pdf/2303.15597)**  \n",
    "  This study highlighted a growing disparity between the academic courses that aspiring software engineers take and the practical work they perform on the job. It emphasized the lack of courses on cloud computing and related technologies, suggesting that universities update their curricula more frequently to remain relevant to industry demands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCSD is ranked third by US News and World Report among UC schools for computer science, so we expect that its curriculum is comparable, if not stronger than other UCs. We predict that UCSD's computer science curriculum prepares students as well as other UCs for industry needs, given its strong ranking. If significant gaps exist, they may be systemic across UC programs rather than specific to UCSD. However, if UCSD shows stronger alignment with industry standards, this may indicate that higher-ranked CS programs provide better preparation from academia to the workforce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: Stack Overflow Developer Surveys\n",
    "  - Link to the dataset:https://survey.stackoverflow.co/\n",
    "  - Number of observations: 65,000-80,000 each \n",
    "  - Number of variables: 116\n",
    "\n",
    "We intend to use the the survey results from the past 4 years, from 2021-2024. For our research, the important variables on skills learned will include LanguageHaveWorkedWith, DatabaseHaveWorkedWith, PlatformHaveWorkedWith, WebframeHaveWorkedWith, ToolsTechHaveWorkedWith,MiscTechHaveWorkedWith, EmbeddedHaveWorkedWith and ProfessionalTech, which are all categorical, multi-select string data. Additionally, we want to understand respondents' skillsets in relation to their education level and where they learned these relevant skills, so we will also consider the variables EdLevel (single choice string), DevType (single choice string), Country(single choice string). \n",
    "\n",
    "Note that the csvs were extremely long and contained thousands of obervations, especially across 4 years. Therefore, we had to split each csv into two parts to fit into our github repo, and our dataset #1 is a merged dataframe on the above specified columns. \n",
    "\n",
    "- Dataset #2-10\n",
    "  - Dataset Name:UC CS Courses\n",
    "  - Number of observations: 49-100 each\n",
    "  - Number of variables: 5\n",
    "\n",
    "We webscraped every CS class from the 9 undergrad UCs, collecting course IDs, titles, and descriptions (strings), whether they were upper or lower div (boolean), and used a python package to extract keywords(list of strings) \n",
    "\n",
    "We plan to merge the UC CS Courses together into one dataframe, as we split up the webscraping and collection amongst members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Overflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#2021 survey \n",
    "stack_2021_a = pd.read_csv(\"stack_overflow_survey_2021_1.csv\")\n",
    "stack_2021_b = pd.read_csv(\"stack_overflow_survey_2021_2.csv\")\n",
    "\n",
    "stack_2021 = pd.concat([stack_2021_a, stack_2021_b], ignore_index=True)\n",
    "\n",
    "cols = [\"Country\", \"EdLevel\", \"DevType\", \"LanguageHaveWorkedWith\", \n",
    "        \"DatabaseHaveWorkedWith\", \"PlatformHaveWorkedWith\", \"WebframeHaveWorkedWith\", \n",
    "        \"ToolsTechHaveWorkedWith\", \"MiscTechHaveWorkedWith\"]\n",
    "\n",
    "stack_2021 = stack_2021[cols]\n",
    "\n",
    "#2022 survey \n",
    "stack_2022_a = pd.read_csv(\"stack_overflow_survey_2022_1.csv\")\n",
    "stack_2022_b = pd.read_csv(\"stack_overflow_survey_2022_2.csv\")\n",
    "\n",
    "stack_2022 = pd.concat([stack_2022_a, stack_2022_b], ignore_index=True)\n",
    "\n",
    "cols = [\"Country\", \"EdLevel\", \"DevType\", \"LanguageHaveWorkedWith\", \n",
    "        \"DatabaseHaveWorkedWith\", \"PlatformHaveWorkedWith\", \"WebframeHaveWorkedWith\", \n",
    "        \"ToolsTechHaveWorkedWith\", \"MiscTechHaveWorkedWith\"]\n",
    "\n",
    "stack_2022 = stack_2022[cols]\n",
    "\n",
    "#2023 survey \n",
    "stack_2023_a = pd.read_csv(\"stack_overflow_survey_2023_1.csv\")\n",
    "stack_2023_b = pd.read_csv(\"stack_overflow_survey_2023_2.csv\")\n",
    "\n",
    "stack_2023 = pd.concat([stack_2023_a, stack_2023_b], ignore_index=True)\n",
    "\n",
    "cols = [\"Country\", \"EdLevel\", \"DevType\", \"LanguageHaveWorkedWith\", \n",
    "        \"DatabaseHaveWorkedWith\", \"PlatformHaveWorkedWith\", \"WebframeHaveWorkedWith\", \n",
    "        \"ToolsTechHaveWorkedWith\", \"MiscTechHaveWorkedWith\"]\n",
    "\n",
    "stack_2023 = stack_2023[cols]\n",
    "\n",
    "#2024 survey \n",
    "stack_2024_a = pd.read_csv(\"stack_overflow_survey_2024_1.csv\")\n",
    "stack_2024_b = pd.read_csv(\"stack_overflow_survey_2024_2.csv\")\n",
    "\n",
    "stack_2024 = pd.concat([stack_2024_a, stack_2024_b], ignore_index=True)\n",
    "\n",
    "cols = [\"Country\", \"EdLevel\", \"DevType\", \"LanguageHaveWorkedWith\", \n",
    "        \"DatabaseHaveWorkedWith\", \"PlatformHaveWorkedWith\", \"WebframeHaveWorkedWith\", \n",
    "        \"ToolsTechHaveWorkedWith\", \"MiscTechHaveWorkedWith\"]\n",
    "\n",
    "stack_2024 = stack_2024[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UC Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:05<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "#UC Berkeley\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from keybert import KeyBERT\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "berk = \"https://guide.berkeley.edu/courses/compsci/\"\n",
    "berk_req = requests.get(berk)\n",
    "soup = BeautifulSoup(berk_req.text, \"html.parser\")\n",
    "\n",
    "divs = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "\n",
    "\n",
    "class_id = []\n",
    "class_title = []\n",
    "desc = []\n",
    "upper = []\n",
    "\n",
    "for div in divs:\n",
    "    heading = div.find(\"p\", class_=\"course-heading\")\n",
    "\n",
    "    if heading:\n",
    "        course_code = div.find(\"span\", class_=\"code\")\n",
    "        course_title = div.find(\"span\", class_=\"title\")\n",
    "        course_desc = div.find(class_=\"courseblockdesc\")\n",
    "\n",
    "        course_details = div.find_all(\"p\")\n",
    "        is_undergrad = any(\"Undergraduate\" in p.text for p in course_details)\n",
    "\n",
    "        if is_undergrad:  \n",
    "            course_id_text = course_code.text.strip()\n",
    "            class_id.append(course_id_text)\n",
    "            class_title.append(course_title.text.strip())\n",
    "            desc.append(course_desc.text.split('\\n')[1])\n",
    "\n",
    "           \n",
    "            course_number = int(\"\".join(filter(str.isdigit, course_id_text)))  # Extract numeric part\n",
    "            is_upper = course_number >= 100\n",
    "            upper.append(is_upper)  \n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Course ID\": class_id,\n",
    "    \"Course Title\": class_title,\n",
    "    \"Course Description\": desc,\n",
    "    \"Upper Div\": upper  \n",
    "})\n",
    "\n",
    "\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT()\n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "    \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\",\n",
    "    \"approach\", \"aspects\", \"awarded\",\n",
    "    \"concepts\", \"course\", \"courses\", \"credit\", \"design\", \"fields\",\n",
    "    \"foundation\", \"fundamental\", \"fundamentals\", \"introduction\", \"issues\", \"level\",\n",
    "    \"lower\", \"major\", \"methods\", \"none\", \"overview\", \"perspectives\",\n",
    "    \"practice\", \"practices\", \"principles\", \"process\", \"processes\",\n",
    "    \"programs\", \"related\", \"required\", \"requirement\", \"role\",\n",
    "    \"skills\", \"study\", \"techniques\", \"tools\", \"topics\", \"understanding\",\n",
    "    \"upper\", \"various\", \"work\"] #dont consider these words  # Extract top 10 keywords\n",
    "\n",
    "\n",
    "df['keywords'] = df['Course Description'].progress_apply(keyword_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:58<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 58.812450885772705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#UC Merced\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "from keybert import KeyBERT\n",
    "\n",
    "UCM_home_url = \"https://catalog.ucmerced.edu/content.php?filter%5B27%5D=CSE&filter%5B29%5D=&filter%5Bkeyword%5D=&filter%5B32%5D=1&filter%5Bcpage%5D=1&cur_cat_oid=23&expand=&navoid=2517&search_database=Filter#acalog_template_course_filter\"\n",
    "\n",
    "response = requests.get(UCM_home_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = [soup.find_all(\"td\", class_=\"width\")[i].find_all('a')[0] for i in range(len(soup.find_all(\"td\", class_=\"width\")))]\n",
    "    coids = [links[i]['href'][-5:] for i in range(len(links))]\n",
    "    full_links = [f'https://catalog.ucmerced.edu/preview_course_nopop.php?catoid=23&coid={course}' for course in coids]\n",
    "else:\n",
    "    print('Request failed:', response.status_code)\n",
    "\n",
    "data = []\n",
    "for url in full_links:\n",
    "    resposne = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        rendered_html = driver.page_source\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        soup = BeautifulSoup(rendered_html, \"html.parser\")\n",
    "\n",
    "        soup = soup.find('td', class_ = 'block_content')\n",
    "\n",
    "        header = soup.find(\"h1\", id=\"course_preview_title\")\n",
    "\n",
    "        header_text = header.get_text(strip=True)\n",
    "        course_code, course_title = [part.strip() for part in header_text.split(\":\", 1)]\n",
    "\n",
    "        course_description = \"\"\n",
    "        for br in soup.find_all(\"br\"):\n",
    "            next_text = br.next_sibling\n",
    "            if next_text and isinstance(next_text, str):\n",
    "                cleaned = next_text.strip()\n",
    "                if cleaned and \"Unit\" not in cleaned:\n",
    "                    course_description = cleaned\n",
    "                    break\n",
    "\n",
    "        result = [course_code, course_title, course_description]\n",
    "        data.append(result)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print('Request failed:', response.status_code)\n",
    "\n",
    "df = pd.DataFrame(columns = ['Course ID', 'Course Title', 'Description'], data=data)\n",
    "\n",
    "df['Upper Div'] = df['Course ID'].str.extract(r'(\\d+)')[0].astype(int).apply(lambda x: x >= 100) #Upper div class is 100-199 class\n",
    "\n",
    "start = time.time() #time it\n",
    "tqdm.pandas() #time it\n",
    "\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT() #instantiate model\n",
    "    \n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "    \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\",\n",
    "    \"approach\", \"aspects\", \"awarded\",\n",
    "    \"concepts\", \"course\", \"courses\", \"credit\", \"design\", \"fields\",\n",
    "    \"foundation\", \"fundamental\", \"fundamentals\", \"introduction\", \"issues\", \"level\",\n",
    "    \"lower\", \"major\", \"methods\", \"none\", \"overview\", \"perspectives\",\n",
    "    \"practice\", \"practices\", \"principles\", \"process\", \"processes\",\n",
    "    \"programs\", \"related\", \"required\", \"requirement\", \"role\",\n",
    "    \"skills\", \"study\", \"techniques\", \"tools\", \"topics\", \"understanding\",\n",
    "    \"upper\", \"various\", \"work\"] #dont consider these words\n",
    "\n",
    "    return [i[0] for i in kw_model.extract_keywords(doc, stop_words=stop_words, top_n=10)] #top 10 keywords\n",
    "\n",
    "df['keywords'] = df['Description'].progress_apply(keyword_wrapper) #apply functon\n",
    "df.head()\n",
    "end = time.time()\n",
    "print('Time:', end - start) #print time\n",
    "\n",
    "df= df[['Course ID',\t'Course Title',\t'Upper Div',\t'keywords']]\n",
    "df.columns = ['Course ID', 'Course Title', 'Upper', 'Skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [03:02<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "#UCD \n",
    "ucd_url = \"https://catalog.ucdavis.edu/courses-subject-code/ecs/\"\n",
    "req = requests.get(ucd_url)\n",
    "soup = BeautifulSoup(req.text)\n",
    "\n",
    "divs = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "\n",
    "class_id = []\n",
    "class_title = []\n",
    "desc = []\n",
    "\n",
    "\n",
    "for div in divs:\n",
    "    code_element = div.find(\"span\", class_=\"text courseblockdetail detail-code margin--span text--semibold text--big\")\n",
    "    title_element = div.find(\"span\", class_=\"text courseblockdetail detail-title margin--span text--semibold text--big\")\n",
    "    desc_element = div.find(\"p\", class_= \"courseblockextra noindent\")\n",
    "\n",
    "    class_id.append(code_element.text.strip())\n",
    "    class_title.append(title_element.text.strip().replace('—', \"\"))\n",
    "    desc.append(desc_element.text.split(\"Course Description:\")[1])\n",
    "\n",
    "df = pd.DataFrame({\"Course ID\": class_id, \"Course Title\": class_title, \"Course Description\":desc})\n",
    "\n",
    "df[\"Upper Div\"] = df[\"Course ID\"].str.extract(r'(\\d+)')[0].astype(int).apply(lambda x:x>=100)\n",
    "df = df[df[\"Course ID\"].str.extract(r'(\\d+)')[0].astype(int) < 200]\n",
    "\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT() #instantiate model\n",
    "    \n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "                  \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\"] #dont consider these words\n",
    "\n",
    "    return [i[0] for i in kw_model.extract_keywords(doc, stop_words=stop_words, top_n=10)] #top 10 keywords\n",
    "\n",
    "df['keywords'] = df['Course Description'].progress_apply(keyword_wrapper) #apply functon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UC Irvine \n",
    "uci_url = 'https://catalogue.uci.edu/allcourses/compsci/'\n",
    "req = requests.get(uci_url)\n",
    "soup = BeautifulSoup(req.text)\n",
    "divs = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "\n",
    "class_id = []\n",
    "class_title = []\n",
    "desc = []\n",
    "upper = []\n",
    "\n",
    "for div in divs:\n",
    "    # Extract Course ID and Title\n",
    "    title_element = div.find(\"p\", class_=\"courseblocktitle\")\n",
    "    if title_element:\n",
    "        full_title = title_element.get_text(strip=True)\n",
    "        course_code, course_name = full_title.split('.', 1)\n",
    "        course_number = int(\"\".join(filter(str.isdigit, course_code)))\n",
    "        if course_number < 200:\n",
    "            class_id.append(course_code.strip())\n",
    "            class_title.append(course_name.split('.')[0].strip())\n",
    "\n",
    "            desc_element = div.find(\"div\", class_=\"courseblockdesc\")\n",
    "            desc_text = []\n",
    "            if desc_element:\n",
    "                for p in desc_element.find_all(\"p\"):\n",
    "                    desc_text.append(p.get_text(strip=True))\n",
    "            desc.append(\" \".join(desc_text))\n",
    "            if course_number >= 100:\n",
    "                upper.append(True)\n",
    "            else:\n",
    "                upper.append(False)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Course ID\": class_id,\n",
    "    \"Course Title\": class_title,\n",
    "    \"Upper\": upper,\n",
    "    \"Skills\": desc\n",
    "})\n",
    "\n",
    "def clean_description(text):\n",
    "    text = text.split(\"Prerequisite:\")[0]\n",
    "    text = text.split(\"Restriction:\")[0]\n",
    "    return text.strip()\n",
    "\n",
    "df['Skills']= df['Skills'].apply(clean_description)\n",
    "\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT() #instantiate model\n",
    "    \n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "                  \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\", \"students\"] #dont consider these words\n",
    "\n",
    "    return [i[0] for i in kw_model.extract_keywords(doc, stop_words=stop_words, top_n=10)] #top 10 keywords\n",
    "\n",
    "df['Skills'] = df['Skills'].apply(keyword_wrapper) #apply functon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course</th>\n",
       "      <th>Course Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGR 001</td>\n",
       "      <td>Professional Development and Mentoring</td>\n",
       "      <td>1 Unit, Activity, 30 hours per quarter. Provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGR 101</td>\n",
       "      <td>Professional Development and Mentoring</td>\n",
       "      <td>1 Unit, Activity, 30 hours per quarter. Prereq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENGR 180W</td>\n",
       "      <td>Technical Communications</td>\n",
       "      <td>4 Units, Lecture, 3 hours; workshop, 3 hours. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS 005</td>\n",
       "      <td>Introduction to Computer Programming</td>\n",
       "      <td>4 Units, Lecture, 3 hours; laboratory,2 hours;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS 006</td>\n",
       "      <td>Effective Use of the World Wide Web</td>\n",
       "      <td>4 Units, Lecture, 3 hours; laboratory, 3 hours...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Course                            Course Title  \\\n",
       "0   ENGR 001  Professional Development and Mentoring   \n",
       "1   ENGR 101  Professional Development and Mentoring   \n",
       "2  ENGR 180W                Technical Communications   \n",
       "3     CS 005    Introduction to Computer Programming   \n",
       "4     CS 006     Effective Use of the World Wide Web   \n",
       "\n",
       "                                         Description  \n",
       "0  1 Unit, Activity, 30 hours per quarter. Provid...  \n",
       "1  1 Unit, Activity, 30 hours per quarter. Prereq...  \n",
       "2  4 Units, Lecture, 3 hours; workshop, 3 hours. ...  \n",
       "3  4 Units, Lecture, 3 hours; laboratory,2 hours;...  \n",
       "4  4 Units, Lecture, 3 hours; laboratory, 3 hours...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:48<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 108.90000176429749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#UC Riverside\n",
    "UCR_url = \"https://www1.cs.ucr.edu/undergraduate/course-descriptions\"\n",
    "\n",
    "response = requests.get(UCR_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(\"table\", class_=\"ui yellow definition striped table\")\n",
    "\n",
    "    header = tables[0].find_all('tr')[0].text.split('\\n')[1:4]\n",
    "\n",
    "    data = [tables[0].find_all('tr')[i].text.split('\\n')[1:4] for i in range(1, len(tables[0].find_all('tr')))]\n",
    "\n",
    "    df = pd.DataFrame(data, columns = header)\n",
    "\n",
    "    \n",
    "    display(df.head())\n",
    "\n",
    "else:\n",
    "    print('response failed:', response.status_code)\n",
    "\n",
    "    df = df[df['Course'].str[:2]==('CS')].reset_index().drop(columns = ['index']) #remove non-cs courses\n",
    "\n",
    "df['Upper Div'] = df['Course'].str.extract(r'(\\d+)')[0].astype(int).apply(lambda x: x >= 100) #Upper div class is 100-199 class\n",
    "\n",
    "\n",
    "def remove_prereq(doc):\n",
    "    doc = re.sub(r'^.*?Prerequisite\\(s\\):.*?(\\.|\\n)', '', doc, flags=re.DOTALL).strip() #remove prerequisites\n",
    "    \n",
    "    #for first class\n",
    "    doc = re.sub(r'4 Units, Lecture, 3 hours; laboratory,2 hours; individual study, 1 hour\\.', '', doc).strip()\n",
    "    \n",
    "    return doc\n",
    "\n",
    "\n",
    "\n",
    "df['Description'] = df['Description'].apply(remove_prereq)\n",
    "\n",
    "start = time.time() #time it\n",
    "tqdm.pandas() #time it\n",
    "\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT() #instantiate model\n",
    "    \n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "    \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\",\n",
    "    \"approach\", \"aspects\", \"awarded\",\n",
    "    \"concepts\", \"course\", \"courses\", \"credit\", \"design\", \"fields\",\n",
    "    \"foundation\", \"fundamental\", \"fundamentals\", \"introduction\", \"issues\", \"level\",\n",
    "    \"lower\", \"major\", \"methods\", \"none\", \"overview\", \"perspectives\",\n",
    "    \"practice\", \"practices\", \"principles\", \"process\", \"processes\",\n",
    "    \"programs\", \"related\", \"required\", \"requirement\", \"role\",\n",
    "    \"skills\", \"study\", \"techniques\", \"tools\", \"topics\", \"understanding\",\n",
    "    \"upper\", \"various\", \"work\"] #dont consider these words\n",
    "\n",
    "    return [i[0] for i in kw_model.extract_keywords(doc, stop_words=stop_words, top_n=10)] #top 10 keywords\n",
    "\n",
    "df['keywords'] = df['Description'].progress_apply(keyword_wrapper) #apply functon\n",
    "df.head()\n",
    "end = time.time()\n",
    "print('Time:', end - start) #print time\n",
    "\n",
    "df = df.drop(columns = ['Description'])\n",
    "df.columns = ['Course ID', 'Course Title', 'Upper', 'Skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [02:57<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 177.55299544334412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#UCSD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "from keybert import KeyBERT\n",
    "UCR_url = \"https://catalog.ucsd.edu/courses/CSE.html\"\n",
    "\n",
    "response = requests.get(UCR_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    div = soup.find('div', class_ = \"col-md-12 blank-slate\")\n",
    "\n",
    "    courses = [i.text.strip().split('.') for i in div.find_all('p', class_ = 'course-name')]\n",
    "    courses = [course for course in courses if int(re.search(r'\\d+', course[0]).group()) < 200]\n",
    "\n",
    "    for course in courses:\n",
    "        course[1] = re.sub(r'\\s*\\(\\d+.*$', '', course[1])\n",
    "    \n",
    "    descriptions = [i.text for i in div.find_all('p', class_ = 'course-descriptions')]\n",
    "\n",
    "    filtered_descriptions = [\n",
    "    description.split('Prerequisites')[0]\n",
    "    for name, description in zip(courses, descriptions)\n",
    "    if int(re.search(r'\\d+', name[0]).group()) < 200\n",
    "]\n",
    "\n",
    "    data = [courses[i] +  [filtered_descriptions[i]] for i in range(len(courses))]\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Course ID', 'Course Title', 'Description'], data=data)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print('response failed:', response.status_code)\n",
    "\n",
    "df['Upper Div'] = df['Course ID'].str.extract(r'(\\d+)')[0].astype(int).apply(lambda x: x >= 100) #Upper div class is 100-199 class\n",
    "\n",
    "\n",
    "start = time.time() #time it\n",
    "tqdm.pandas() #time it\n",
    "\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT() #instantiate model\n",
    "    \n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "    \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\",\n",
    "    \"approach\", \"aspects\", \"awarded\",\n",
    "    \"concepts\", \"course\", \"courses\", \"credit\", \"design\", \"fields\",\n",
    "    \"foundation\", \"fundamental\", \"fundamentals\", \"introduction\", \"issues\", \"level\",\n",
    "    \"lower\", \"major\", \"methods\", \"none\", \"overview\", \"perspectives\",\n",
    "    \"practice\", \"practices\", \"principles\", \"process\", \"processes\",\n",
    "    \"programs\", \"related\", \"required\", \"requirement\", \"role\",\n",
    "    \"skills\", \"study\", \"techniques\", \"tools\", \"topics\", \"understanding\",\n",
    "    \"upper\", \"various\", \"work\"] #dont consider these words\n",
    "\n",
    "    return [i[0] for i in kw_model.extract_keywords(doc, stop_words=stop_words, top_n=10)] #top 10 keywords\n",
    "\n",
    "df['keywords'] = df['Description'].progress_apply(keyword_wrapper) #apply functon\n",
    "\n",
    "end = time.time()\n",
    "print('Time:', end - start) #print time\n",
    "\n",
    "df = df.drop(columns=['Description'])\n",
    "df['Skills'] = df['keywords']\n",
    "df = df.drop(columns=['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [01:37<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 97.55204701423645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#UCLA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "from keybert import KeyBERT\n",
    "\n",
    "url = \"https://registrar.ucla.edu/academics/course-descriptions?search=COM+SCI\"\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "rendered_html = driver.page_source\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "soup = BeautifulSoup(rendered_html, \"html.parser\")\n",
    "\n",
    "\n",
    "upper_div_section = soup.find('div', {'aria-labelledby': 'upper-division-courses-51-1'})\n",
    "    \n",
    "lower_div_section = soup.find('div', {'aria-labelledby': 'lower-division-courses-10-1'})\n",
    "\n",
    "undergrad_courses = []\n",
    "\n",
    "if lower_div_section:\n",
    "        course_records = lower_div_section.find_all('div', class_='course-record')\n",
    "        for record in course_records:\n",
    "            title_element = record.find('h3')\n",
    "            description_paragraphs = record.find_all('p')\n",
    "\n",
    "            if title_element and description_paragraphs:\n",
    "                full_title = title_element.text.strip()\n",
    "                parts = full_title.split('.', 1)\n",
    "                if len(parts) == 2:\n",
    "                    course_code = \"CS \" + parts[0].strip()\n",
    "                    course_title = parts[1].strip()\n",
    "                else:\n",
    "                    course_code = \"CS Unknown\"\n",
    "                    course_title = full_title\n",
    "                description = '\\n'.join(p.text.strip() for p in description_paragraphs[1:])\n",
    "                undergrad_courses.append([course_code, course_title, description])\n",
    "\n",
    "if upper_div_section:\n",
    "    course_records = upper_div_section.find_all('div', class_='course-record')\n",
    "    for record in course_records:\n",
    "        title_element = record.find('h3')\n",
    "        description_paragraphs = record.find_all('p')\n",
    "\n",
    "        if title_element and description_paragraphs:\n",
    "            full_title = title_element.text.strip()\n",
    "            parts = full_title.split('.', 1)\n",
    "            if len(parts) == 2:\n",
    "                course_code = \"CS \" + parts[0].strip()\n",
    "                course_title = parts[1].strip()\n",
    "            else:\n",
    "                course_code = \"CS Unknown\"\n",
    "                course_title = full_title\n",
    "            description = '\\n'.join(p.text.strip() for p in description_paragraphs[1:])\n",
    "            undergrad_courses.append([course_code, course_title, description])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns = ['Course ID', 'Course Title', 'Description'], data = undergrad_courses)\n",
    "\n",
    "\n",
    "\n",
    "def extract_description(text):\n",
    "    try:\n",
    "        parts = text.split('.', 1) \n",
    "        if len(parts) < 2: \n",
    "          return text\n",
    "        description_start = parts[1].strip()\n",
    "\n",
    "        if \"grading\" in description_start.lower():\n",
    "            description_parts = description_start.split(\"grading\")\n",
    "            core_description = description_parts[0].strip()\n",
    "        else:\n",
    "            core_description = description_start\n",
    "\n",
    "        return core_description\n",
    "\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "df['Description'] = df['Description'].apply(extract_description)\n",
    "\n",
    "df['Upper Div'] = df['Course ID'].str.extract(r'(\\d+)')[0].astype(int).apply(lambda x: x >= 100) #Upper div class is 100-199 class\n",
    "\n",
    "start = time.time() #time it\n",
    "tqdm.pandas() #time it\n",
    "\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT() #instantiate model\n",
    "    \n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "    \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\",\n",
    "    \"approach\", \"aspects\", \"awarded\",\n",
    "    \"concepts\", \"course\", \"courses\", \"credit\", \"design\", \"fields\",\n",
    "    \"foundation\", \"fundamental\", \"fundamentals\", \"introduction\", \"issues\", \"level\",\n",
    "    \"lower\", \"major\", \"methods\", \"none\", \"overview\", \"perspectives\",\n",
    "    \"practice\", \"practices\", \"principles\", \"process\", \"processes\",\n",
    "    \"programs\", \"related\", \"required\", \"requirement\", \"role\",\n",
    "    \"skills\", \"study\", \"techniques\", \"tools\", \"topics\", \"understanding\",\n",
    "    \"upper\", \"various\", \"work\", \"department\", \"resources\", \"requisite\", \"requisites\", \"enforced\", \"lecture\", \"hours\"] #dont consider these words\n",
    "\n",
    "    return [i[0] for i in kw_model.extract_keywords(doc, stop_words=stop_words, top_n=10)] #top 10 keywords\n",
    "\n",
    "df['keywords'] = df['Description'].progress_apply(keyword_wrapper) #apply functon\n",
    "df.head()\n",
    "end = time.time()\n",
    "print('Time:', end - start) #print time\n",
    "\n",
    "df = df.drop(columns=['Description'])\n",
    "\n",
    "df['Skills'] = df['keywords']\n",
    "df = df.drop(columns=['keywords'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ucsc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from keybert import KeyBERT\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "ucsc_url = 'https://registrar.ucsc.edu/catalog/archive/11-12/programs-courses/course-descriptions/cmpscourses.html'\n",
    "req = requests.get(ucsc_url)\n",
    "soup = BeautifulSoup(req.text)\n",
    "\n",
    "course_blocks = soup.find_all(\"p\")\n",
    "\n",
    "class_id = []\n",
    "class_title = []\n",
    "desc = []\n",
    "upper = []\n",
    "def clean_description(text):\n",
    "    text = text.replace('(2 credits)','')\n",
    "    text = text.split(\"Students cannot\")[0]\n",
    "    text = text.split(\"Prerequisite(s):\")[0] \n",
    "    text = text.split(\"(General Education Codes(s):\")[0]\n",
    "    text = text.replace(\"F,W,S\",\"\").replace(\"F,W\",\"\").replace(\"W,S\",\"\").replace(\"F,S\",\"\").replace(\"*\",\"\")\n",
    "    return text.strip()\n",
    "\n",
    "for i in range(len(course_blocks)):\n",
    "    course_text = course_blocks[i].get_text(strip=True)\n",
    "    if re.match(r\"^\\d+[A-Z]?\\.\", course_text):\n",
    "        split_text = course_text.split(\".\", 1)\n",
    "        course_code = split_text[0].strip() \n",
    "        course_name = split_text[1].strip() \n",
    "\n",
    "        course_number = int(\"\".join(filter(str.isdigit, course_code)))\n",
    "\n",
    "        if course_number < 200:\n",
    "            class_id.append(course_code)\n",
    "            class_title.append(clean_description(course_name).split('.')[0])\n",
    "            desc_element = course_blocks[i + 1].get_text(strip=True) if i + 1 < len(course_blocks) else \"\"\n",
    "            desc.append(clean_description(desc_element).split('.')[2])\n",
    "            upper.append(course_number >= 100)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Course ID\": class_id,\n",
    "    \"Course Title\": class_title,\n",
    "    \"Upper\": upper,\n",
    "    \"Skills\": desc\n",
    "})\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT() #instantiate model\n",
    "    \n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "    \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\",\n",
    "    \"approach\", \"aspects\", \"awarded\",\n",
    "    \"concepts\", \"course\", \"courses\", \"credit\", \"design\", \"fields\",\n",
    "    \"foundation\", \"fundamental\", \"fundamentals\", \"introduction\", \"issues\", \"level\",\n",
    "    \"lower\", \"major\", \"methods\", \"none\", \"overview\", \"perspectives\",\n",
    "    \"practice\", \"practices\", \"principles\", \"process\", \"processes\",\n",
    "    \"programs\", \"related\", \"required\", \"requirement\", \"role\",\n",
    "    \"skills\", \"study\", \"techniques\", \"tools\", \"topics\", \"understanding\",\n",
    "    \"upper\", \"various\", \"work\", \"department\", \"resources\", \"requisite\", \"requisites\", \"enforced\", \"lecture\", \"hours\"] #dont consider these words\n",
    "\n",
    "    return [i[0] for i in kw_model.extract_keywords(doc, stop_words=stop_words, top_n=10)] #top 10 keywords\n",
    "\n",
    "df['Skills'] = df['Skills'].apply(keyword_wrapper) #apply functon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:12<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 72.50465130805969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ucsb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "from keybert import KeyBERT\n",
    "\n",
    "url = \"https://cs.ucsb.edu/education/courses/course-descriptions\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    table = soup.find('table', class_ = \"table table-hover table-striped\").find_all('td', class_ = \"views-field views-field-title\")\n",
    "\n",
    "\n",
    "    urls = [\"https://cs.ucsb.edu\"+i.find('a')['href'] for i in table]\n",
    "\n",
    "else:\n",
    "    print('response failed:', response.status_code)\n",
    "\n",
    "\n",
    "metadata_keys = [\"Prerequisite\", \"Enrollment Comments\", \"Repeat Comments\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "def clean_paragraph(text):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if any(sentence.startswith(key) for key in metadata_keys):\n",
    "            continue\n",
    "        if sentence:  \n",
    "            cleaned_sentences.append(sentence)\n",
    "    return \" \".join(cleaned_sentences)\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    under_grad = soup.find_all('div', class_=\"field--item\")\n",
    "    \n",
    "    if under_grad[3].text == \"Undergraduate\":\n",
    "        course = under_grad[1].text\n",
    "        title = soup.find('h1', class_=\"page-header\").text.strip()\n",
    "        desc_tags = soup.find('div', class_=\"field field--name-field-course-des field--type-text-long field--label-above\") \\\n",
    "                        .find('div', class_=\"field--item\") \\\n",
    "                        .find_all(\"p\")\n",
    "        \n",
    "        cleaned_descs = []\n",
    "        for p in desc_tags:\n",
    "            text = p.get_text(\" \", strip=True)\n",
    "            if any(text.startswith(key) for key in metadata_keys):\n",
    "                cleaned_text = clean_paragraph(text)\n",
    "            else:\n",
    "                cleaned_text = text\n",
    "            if cleaned_text:\n",
    "                cleaned_descs.append(cleaned_text)\n",
    "                \n",
    "        final_desc = \" \".join(cleaned_descs)\n",
    "\n",
    "        result = [course, title, final_desc]\n",
    "        data.append(result)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns = ['Course ID', 'Course Title', 'Description'], data=data)\n",
    "\n",
    "df['Upper Div'] = df['Course ID'].str.extract(r'(\\d+)')[0].astype(int).apply(lambda x: x >= 100) #Upper div class is 100-199 class\n",
    "\n",
    "\n",
    "start = time.time() #time it\n",
    "tqdm.pandas() #time it\n",
    "\n",
    "def keyword_wrapper(doc):\n",
    "    kw_model = KeyBERT() #instantiate model\n",
    "    \n",
    "    stop_words = [\"cs\", \"prerequisite\", \"grade\", \"requirement\", \n",
    "    \"courses\", \"instructor\", \"faculty\", \"computer\", \"student\", \"concurrently\", \"majors\",\n",
    "    \"approach\", \"aspects\", \"awarded\",\n",
    "    \"concepts\", \"course\", \"courses\", \"credit\", \"design\", \"fields\",\n",
    "    \"foundation\", \"fundamental\", \"fundamentals\", \"introduction\", \"issues\", \"level\",\n",
    "    \"lower\", \"major\", \"methods\", \"none\", \"overview\", \"perspectives\",\n",
    "    \"practice\", \"practices\", \"principles\", \"process\", \"processes\",\n",
    "    \"programs\", \"related\", \"required\", \"requirement\", \"role\",\n",
    "    \"skills\", \"study\", \"techniques\", \"tools\", \"topics\", \"understanding\",\n",
    "    \"upper\", \"various\", \"work\"] #dont consider these words\n",
    "\n",
    "    return [i[0] for i in kw_model.extract_keywords(doc, stop_words=stop_words, top_n=10)] #top 10 keywords\n",
    "\n",
    "df['keywords'] = df['Description'].progress_apply(keyword_wrapper) #apply functon\n",
    "df.head()\n",
    "end = time.time()\n",
    "print('Time:', end - start) #print time\n",
    "\n",
    "\n",
    "df = df.drop(columns=['Description'])\n",
    "df['Skills'] = df['keywords']\n",
    "df = df.drop(columns=['keywords'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluding that UCSD does not adequately prepare students for the workforce could negatively impact the university's reputation and discourage prospective students. This may be a misinterpretation of the university's ability to prepare students, as it is a large research university, and many skills can be learned through on site research programs that teach technologies not outlined in the curriculum. \n",
    "\n",
    "PRIVACY: There are no significant privacy concerns in this research as the primary data—university curriculums, reported technologies, and publicly available surveys (e.g., Stack Overflow)—is already accessible to the public. \n",
    "\n",
    "BIASES: \n",
    "\n",
    "Funding Disparities : Universities with more funding may offer more thorough curriculums, teaching more languages, libraries, and frameworks than others. Thus, they have a higher correlation to tools used in jobs, skewing the analysis toward their favor. The same holds for UCs with higher prestige / reputations. \n",
    "\n",
    "However, UCSD is not the most nor least reputable UC. As a result, the more / less prestugous may even out to dappen the effect of funding. \n",
    "\n",
    "Bias in Survey Respondents: \n",
    "Our main source of data comes from the Stack Overflow 2024 Developer Survey, in which 65,000 respondents from 185 countries answered questions. Our question analyzes the curriculums of UCs, and it is safe to assume most UC CS graduates remain within the country. Therefore, respondents from the other 184 countries may use different technologies, some of which may not be taught in UC curriculums. \n",
    "\n",
    "Grouping UCs for Curriculum Averages: Taking averages of curriculums across UC campuses could mask differences in quality between individual programs, making the grouped UCs appear stronger. \n",
    "\n",
    "Inclusion of Non-CS Majors in Job Fields: \n",
    "The technologies that developers reported arent necessarily used by only computer science majors. Individuals from related majors (Data Science, Mathematics, Computer Engineering),  could have reported their skills, and thus wont align with what CS majors need to know on the job. As a solution, if possible, we should filter data to include only CS major - reported technologies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* We will discuss through our group discord to discuss anything related to the project.\n",
    "* If we have issues or disagreements, we will communicate politely and through meaningful group discussions.\n",
    "* We will divide up the work equally and all work on our part with care\n",
    "* Jae Kim, Peter Shamoun, Emily Cai, Viki Shi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/05  |  3 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Make Discord Server to communicate; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/09  |  7 PM |  Look for potential topics | Discuss ideal datasets and ethics; submit project proposal | \n",
    "| 2/16  | 7 PM  | Look for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/21  | 2 PM  | Import & Wrangle Data | Review/Edit data; Complete Checkpoint #1- data   |\n",
    "| 3/09  | 7 PM  | Finalize wrangling/EDA; Begin Analysis | Discuss/edit Analysis; Complete Checkpoint#2- EDA |\n",
    "| 3/15  | 7 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
